{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import csv\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "\n",
    "from nbeats_pytorch.model import NBeatsNet \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into batches without bootstrap and shuffling (for testing)\n",
    "def split(arr, size):\n",
    "    arrays = []\n",
    "    while len(arr) > size:\n",
    "        slice_ = arr[:size]\n",
    "        arrays.append(slice_)\n",
    "        arr = arr[size:]\n",
    "    arrays.append(arr)\n",
    "    return arrays\n",
    "\n",
    "# split data into batches with bootstrap\n",
    "def bootstrap_batch(arr, target, size):\n",
    "    idx = np.random.choice(len(arr), size, replace=True)\n",
    "    return arr[idx], target[idx]\n",
    "\n",
    "# data generator\n",
    "def batcher(x, y, batch_size, infinite=False):\n",
    "    if infinite: # training\n",
    "        while True:\n",
    "            x_, y_ = bootstrap_batch(x, y, batch_size)\n",
    "            yield x_, y_\n",
    "    else: # evaluating\n",
    "        for x_, y_ in zip(split(x, batch_size), split(y, batch_size)):\n",
    "            yield x_, y_\n",
    "\n",
    "# save model to file\n",
    "def save(model, optimiser, grad_step, checkpoint_name):\n",
    "    torch.save({\n",
    "        'grad_step': grad_step,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimiser.state_dict(),\n",
    "    }, checkpoint_name)\n",
    "\n",
    "# load model from file\n",
    "def load(model, checkpoint_name, optimiser=None):\n",
    "    if os.path.exists(checkpoint_name):\n",
    "        checkpoint = torch.load(checkpoint_name)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        if optimiser is not None:\n",
    "            optimiser.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        grad_step = checkpoint['grad_step']\n",
    "        print(f'Restored checkpoint from {checkpoint_name}.')\n",
    "        return grad_step\n",
    "    return 0\n",
    "\n",
    "# plots forecast of a model into a file\n",
    "def plot_model_forecast(x, target, forecast, backcast_length, forecast_length, grad_step):\n",
    "\n",
    "    fig, ax = plt.subplots(ncols=3, nrows=3, figsize=(8, 8))\n",
    "    plt.subplots_adjust(top=0.88)\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            index = 3 * i + j\n",
    "            ff, xx, yy = forecast[index], x[index], target[index]\n",
    "            ax[i, j].plot(range(0, backcast_length), xx, color='b')\n",
    "            ax[i, j].plot(range(backcast_length, backcast_length + \\\n",
    "                                forecast_length), yy, color='g')\n",
    "            ax[i, j].plot(range(backcast_length, backcast_length + \\\n",
    "                                forecast_length), ff, color='r')\n",
    "\n",
    "    \n",
    "    output = 'n_beats_{}.png'.format(grad_step)\n",
    "    plt.savefig(output)\n",
    "    plt.clf()\n",
    "    print('Saved image to {}.'.format(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to load different datasets for evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_m4_data_testing(backcast_length, forecast_length, data_type):\n",
    "\n",
    "    # for training on different frequencies the path to a nesessary data file \n",
    "    # must be modified\n",
    "    \n",
    "    data_type = data_type[0].upper() + data_type[1:]\n",
    "\n",
    "    x_ts = []\n",
    "    headers = True\n",
    "    with open('./data/m4/{}-train.csv'.format(data_type), \"r\") as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for line in reader:\n",
    "            line = line[1:]\n",
    "            if not headers:\n",
    "                x_ts.append(line)\n",
    "            if headers:\n",
    "                headers = False\n",
    "    x_ts_train = np.array(x_ts)\n",
    "    \n",
    "    x_ts = []\n",
    "    headers = True\n",
    "    with open('./data/m4/{}-test.csv'.format(data_type), \"r\") as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for line in reader:\n",
    "            line = line[1:]\n",
    "            if not headers:\n",
    "                x_ts.append(line)\n",
    "            if headers:\n",
    "                headers = False\n",
    "    x_ts_test = np.array(x_ts)\n",
    "    \n",
    "    x = np.empty((x_ts_train.shape[0], backcast_length))\n",
    "    y = np.empty((x_ts_train.shape[0], forecast_length))\n",
    "    \n",
    "    for i in range(x_ts_train.shape[0]):\n",
    "        \n",
    "        time_series = np.array(x_ts_train[i])\n",
    "        time_series = [float(s) for s in time_series if s != '']\n",
    "        time_series_cleaned = np.array(time_series)\n",
    "        \n",
    "        target = np.array(x_ts_test[i])\n",
    "        target = [float(s) for s in target if s != '']\n",
    "        target_cleaned = np.array(target)\n",
    "        \n",
    "        time_series_cleaned_forlearning_x = np.zeros((1, backcast_length))\n",
    "        time_series_cleaned_forlearning_y = np.zeros((1, forecast_length))\n",
    "\n",
    "        nonzero_input = time_series_cleaned[-backcast_length: ]\n",
    "        time_series_cleaned_forlearning_x[0, -len(nonzero_input):] = nonzero_input\n",
    "        time_series_cleaned_forlearning_y[0, : len(target_cleaned)] = target_cleaned\n",
    "\n",
    "        x[i] = time_series_cleaned_forlearning_x\n",
    "        y[i] = time_series_cleaned_forlearning_y\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "def get_m3_data_testing(backcast_length, forecast_length, data_type):\n",
    "\n",
    "    x_ts = []\n",
    "    headers = True\n",
    "    with open('./data/m3/m3_{}.csv'.format(data_type), \"r\") as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for line in reader:\n",
    "            line = line[6:]\n",
    "            if not headers:\n",
    "                x_ts.append(line)\n",
    "            if headers:\n",
    "                headers = False\n",
    "    x_ts_train = np.array(x_ts)\n",
    "    \n",
    "    x = np.empty((x_ts_train.shape[0], backcast_length))\n",
    "    y = np.empty((x_ts_train.shape[0], forecast_length))\n",
    "    \n",
    "    for i in range(x_ts_train.shape[0]):\n",
    "        \n",
    "        time_series = np.array(x_ts_train[i])\n",
    "        time_series = [float(s) for s in time_series if s != '']\n",
    "        time_series_cleaned = np.array(time_series)\n",
    "        \n",
    "        time_series_cleaned_forlearning_x = np.zeros((1, backcast_length))\n",
    "        time_series_cleaned_forlearning_y = np.zeros((1, forecast_length))\n",
    "\n",
    "        nonzero_input = time_series_cleaned\\\n",
    "                [-(backcast_length + forecast_length): -forecast_length]\n",
    "        time_series_cleaned_forlearning_x[0, -len(nonzero_input):] = nonzero_input\n",
    "        nonzero_output = time_series_cleaned[-forecast_length :]\n",
    "        time_series_cleaned_forlearning_y[0, : len(nonzero_output)] = nonzero_output\n",
    "\n",
    "        x[i] = time_series_cleaned_forlearning_x\n",
    "        y[i] = time_series_cleaned_forlearning_y\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "def get_fred_data_testing(backcast_length, forecast_length, data_type):\n",
    "\n",
    "    x_ts = []\n",
    "    with open('./data/fred/{}_final.csv'.format(data_type), \"r\") as file:\n",
    "        reader = csv.reader(file, delimiter=',')\n",
    "        for line in reader:\n",
    "            ts = np.array(line).astype(float)\n",
    "            x_ts.append(ts)\n",
    "            \n",
    "    x_ts_train = np.array(x_ts)\n",
    "        \n",
    "    x = np.empty((x_ts_train.shape[0], backcast_length))\n",
    "    x_start_indexes = np.empty(x_ts_train.shape[0])\n",
    "    y = np.empty((x_ts_train.shape[0], forecast_length))\n",
    "    \n",
    "    for i in range(x_ts_train.shape[0]):\n",
    "        \n",
    "        time_series_cleaned = x_ts_train[i]\n",
    "        \n",
    "        time_series_cleaned_forlearning_x = np.zeros((1, backcast_length))\n",
    "        time_series_cleaned_forlearning_y = np.zeros((1, forecast_length))\n",
    "\n",
    "        nonzero_input = time_series_cleaned\\\n",
    "                [-(backcast_length + forecast_length): -forecast_length]\n",
    "        time_series_cleaned_forlearning_x[0, -len(nonzero_input):] = nonzero_input\n",
    "        x_start_indexes[i] = backcast_length - len(nonzero_input)\n",
    "        \n",
    "        nonzero_output = time_series_cleaned[-forecast_length :]\n",
    "        time_series_cleaned_forlearning_y[0, : len(nonzero_output)] = nonzero_output\n",
    "\n",
    "        x[i] = time_series_cleaned_forlearning_x\n",
    "        y[i] = time_series_cleaned_forlearning_y\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "    return (x, x_start_indexes.astype(int)), y\n",
    "\n",
    "def get_tourism_data_testing(backcast_length, forecast_length, data_type):\n",
    "\n",
    "    # extra fields with metainformation in some frequencies\n",
    "    if data_type == 'yearly':\n",
    "        extra_length = 2\n",
    "    else:\n",
    "        extra_length = 3\n",
    "        \n",
    "    # read train\n",
    "    data_tour = pd.read_csv('./data/tourism/{}-train.csv'.format(data_type))\n",
    "    lengths = data_tour.iloc[0].astype(int).values\n",
    "    data = data_tour.values[extra_length:, :]\n",
    "    \n",
    "    x_ts = []\n",
    "    for i in range(data.shape[1]):\n",
    "        line = data[:lengths[i], i]\n",
    "        x_ts.append(line)\n",
    "\n",
    "    x_ts_train = np.array(x_ts)\n",
    "    \n",
    "    # read test\n",
    "    data_tour = pd.read_csv('./data/tourism/{}-test.csv'.format(data_type))\n",
    "    lengths = data_tour.iloc[0].astype(int).values\n",
    "    data = data_tour.values[extra_length:, :]\n",
    "    \n",
    "    x_ts = []\n",
    "    for i in range(data.shape[1]):\n",
    "        line = data[:lengths[i], i]\n",
    "        x_ts.append(line)\n",
    "\n",
    "    x_ts_test = np.array(x_ts)\n",
    "    \n",
    "    x = np.empty((x_ts_train.shape[0], backcast_length))\n",
    "    y = np.empty((x_ts_train.shape[0], forecast_length))\n",
    "    \n",
    "    for i in range(x_ts_train.shape[0]):\n",
    "        \n",
    "        time_series_cleaned = x_ts_train[i]\n",
    "        target_cleaned = x_ts_test[i][:forecast_length]\n",
    "        \n",
    "        time_series_cleaned_forlearning_x = np.zeros((1, backcast_length))\n",
    "        time_series_cleaned_forlearning_y = np.zeros((1, forecast_length))\n",
    "\n",
    "        nonzero_input = time_series_cleaned[-backcast_length: ]\n",
    "        time_series_cleaned_forlearning_x[0, -len(nonzero_input):] = nonzero_input\n",
    "        time_series_cleaned_forlearning_y[0, : len(target_cleaned)] = target_cleaned\n",
    "\n",
    "        x[i] = time_series_cleaned_forlearning_x\n",
    "        y[i] = time_series_cleaned_forlearning_y\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "def get_electricity_data_testing(backcast_length, forecast_length, data_type):\n",
    "\n",
    "    # read train and test\n",
    "    x_ts_train = np.load('./data/electricity.npy')\n",
    "    \n",
    "    x = np.empty((x_ts_train.shape[1], backcast_length))\n",
    "    y = np.empty((x_ts_train.shape[1], forecast_length))\n",
    "    \n",
    "    for i in range(x_ts_train.shape[1]):\n",
    "        \n",
    "        time_series_cleaned = np.trim_zeros(x_ts_train[:, i], 'f')\n",
    "        \n",
    "        time_series_cleaned_forlearning_x = np.zeros((1, backcast_length))\n",
    "        time_series_cleaned_forlearning_y = np.zeros((1, forecast_length))\n",
    "\n",
    "        nonzero_input = time_series_cleaned\\\n",
    "                [-(backcast_length + forecast_length): -forecast_length]\n",
    "        time_series_cleaned_forlearning_x[0, -len(nonzero_input):] = nonzero_input\n",
    "        nonzero_output = time_series_cleaned[-forecast_length :]\n",
    "        time_series_cleaned_forlearning_y[0, : len(nonzero_output)] = nonzero_output\n",
    "\n",
    "        x[i] = time_series_cleaned_forlearning_x\n",
    "        y[i] = time_series_cleaned_forlearning_y\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "def get_traffic_data_testing(backcast_length, forecast_length, data_type):\n",
    "\n",
    "    # read train and test\n",
    "    x_ts_train = np.load('./data/traffic.npy')\n",
    "    \n",
    "    x = np.empty((x_ts_train.shape[1], backcast_length))\n",
    "    y = np.empty((x_ts_train.shape[1], forecast_length))\n",
    "    \n",
    "    for i in range(x_ts_train.shape[1]):\n",
    "        \n",
    "        time_series_cleaned = np.trim_zeros(x_ts_train[:, i], 'f')\n",
    "        \n",
    "        time_series_cleaned_forlearning_x = np.zeros((1, backcast_length))\n",
    "        time_series_cleaned_forlearning_y = np.zeros((1, forecast_length))\n",
    "\n",
    "        nonzero_input = time_series_cleaned\\\n",
    "                [-(backcast_length + forecast_length): -forecast_length]\n",
    "        time_series_cleaned_forlearning_x[0, -len(nonzero_input):] = nonzero_input\n",
    "        nonzero_output = time_series_cleaned[-forecast_length :]\n",
    "        time_series_cleaned_forlearning_y[0, : len(nonzero_output)] = nonzero_output\n",
    "\n",
    "        x[i] = time_series_cleaned_forlearning_x\n",
    "        y[i] = time_series_cleaned_forlearning_y\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses\n",
    "\n",
    "**Losses for torch.tensors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_loss(output, target):\n",
    "    nonzero_mask = target != 0\n",
    "    target = target[nonzero_mask]\n",
    "    output = output[nonzero_mask]\n",
    "    \n",
    "    numerator = torch.abs(output - target)\n",
    "    denominator = torch.abs(output) + torch.abs(target)\n",
    "    elementwise_smape = torch.div(numerator, denominator)\n",
    "        \n",
    "    nan_mask = torch.isnan(elementwise_smape)\n",
    "    loss = elementwise_smape[~nan_mask].mean() * 200\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def smape_loss_m3(output, target):\n",
    "    nonzero_mask = target != 0\n",
    "    target = target[nonzero_mask]\n",
    "    output = output[nonzero_mask]\n",
    "    \n",
    "    numerator = torch.abs(output - target)\n",
    "    denominator = output + target\n",
    "    elementwise_smape = torch.div(numerator, denominator)\n",
    "        \n",
    "    nan_mask = torch.isnan(elementwise_smape)\n",
    "    loss = elementwise_smape[~nan_mask].mean() * 200\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def mape_loss(output, target):\n",
    "    nonzero_mask = target != 0\n",
    "    target = target[nonzero_mask]\n",
    "    output = output[nonzero_mask]\n",
    "    \n",
    "    numerator = torch.abs(output - target)\n",
    "    denominator = torch.abs(target)\n",
    "    elementwise_smape = torch.div(numerator, denominator)\n",
    "        \n",
    "    nan_mask = torch.isnan(elementwise_smape)\n",
    "    loss = elementwise_smape[~nan_mask].mean() * 100\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def nd_loss(output, target):\n",
    "    nonzero_mask = target != 0\n",
    "    target = target[nonzero_mask]\n",
    "    output = output[nonzero_mask]\n",
    "    \n",
    "    numerator = torch.sum(torch.abs(output - target))\n",
    "    denominator = torch.sum(torch.abs(target))\n",
    "    \n",
    "    loss = numerator / denominator\n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Losses for numpy.arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smape_loss_numpy(output, target):\n",
    "    nonzero_mask = target != 0\n",
    "    target = target[nonzero_mask]\n",
    "    output = output[nonzero_mask]\n",
    "    \n",
    "    numerator = np.abs(output - target)\n",
    "    denominator = np.abs(output) + np.abs(target)\n",
    "    elementwise_smape = numerator / denominator\n",
    "            \n",
    "    nan_mask = np.isnan(elementwise_smape)\n",
    "    loss = elementwise_smape[~nan_mask].mean() * 200\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def smape_loss_m3_numpy(output, target):\n",
    "    nonzero_mask = target != 0\n",
    "    target = target[nonzero_mask]\n",
    "    output = output[nonzero_mask]\n",
    "    \n",
    "    numerator = np.abs(output - target)\n",
    "    denominator = output + target\n",
    "    elementwise_smape = numerator / denominator\n",
    "            \n",
    "    nan_mask = np.isnan(elementwise_smape)\n",
    "    loss = elementwise_smape[~nan_mask].mean() * 200\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def mape_loss_numpy(output, target):\n",
    "    nonzero_mask = target != 0\n",
    "    target = target[nonzero_mask]\n",
    "    output = output[nonzero_mask]\n",
    "    \n",
    "    numerator = np.abs(output - target)\n",
    "    denominator = np.abs(target)\n",
    "    elementwise_smape = numerator / denominator\n",
    "        \n",
    "    nan_mask = np.isnan(elementwise_smape)\n",
    "    loss = elementwise_smape[~nan_mask].mean() * 100\n",
    "    \n",
    "    return loss\n",
    "\n",
    "def nd_loss_numpy(output, target):\n",
    "    nonzero_mask = target != 0\n",
    "    target = target[nonzero_mask]\n",
    "    output = output[nonzero_mask]\n",
    "    \n",
    "    numerator = np.sum(np.abs(output - target))\n",
    "    denominator = np.sum(np.abs(target))\n",
    "    \n",
    "    loss = numerator / denominator\n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to get predictions of any nets on any possible data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(net, data_generator, main_gen, device, loss_func,\\\n",
    "                     checkpoint_name, forecast_length, file, has_neg_values):\n",
    "\n",
    "    global forecast_global\n",
    "    print('--- Evaluating ---')\n",
    "        \n",
    "    initial_grad_step = load(net, checkpoint_name)\n",
    "    net.eval()\n",
    "    losses = []\n",
    "        \n",
    "    for ind, (x, target) in enumerate(main_gen):\n",
    "                       \n",
    "        x_scaled, consts = next(data_generator)\n",
    "        _, forecast = net(torch.tensor(x_scaled, dtype=torch.float))#.to(device))\n",
    "\n",
    "        # descale forecast\n",
    "        if has_neg_values:\n",
    "            print(consts)\n",
    "            print(consts.shape)\n",
    "            max_consts = consts[:, 0]\n",
    "            min_consts = consts[:, 1]\n",
    "            # no need to care about zero padding\n",
    "            # it will be droppped while computing metric\n",
    "            forecast = (forecast.T * (max_consts - min_consts) + min_consts).T\n",
    "        else:\n",
    "            print(consts)\n",
    "            print(consts.shape)\n",
    "            max_consts = consts\n",
    "            forecast = (forecast.T * max_consts).T\n",
    "        \n",
    "        # save predictions to file\n",
    "        forecast.detach().numpy().tofile(file)\n",
    "        \n",
    "        #new\n",
    "        # как-то криво ходит по батчам, как будто сохраняет только один батч\n",
    "        # forecast_global.append(forecast.detach().numpy())\n",
    "                \n",
    "        # compute loss\n",
    "        loss = loss_func(forecast, torch.tensor(target, dtype=torch.float))\n",
    "        losses.append(loss.item())\n",
    "                    \n",
    "    print('Mean loss', np.mean(losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to predict any dataset using any available N-BEATS model\n",
    "\n",
    "Parameters to change:\n",
    "\n",
    "- data_type: frequency of data which is needed to predict. May be yearly, quarterly, monthly, daily, weekly, hourly, other depending on the dataset\n",
    "\n",
    "- train_dataset: 'm4' or 'fred' - dataset on which models were trained\n",
    "\n",
    "- test_dataset: dataset on which we want to get predictions. Can be m4, m3, fred, electricity, traffic, tourism\n",
    "\n",
    "This code uses files CHECKPOINT_NAME in FOLDER as path to trained models - should be changed if you use another path.\n",
    "\n",
    "Also, it saves predictions to file PREDS_FILENAME.\n",
    "\n",
    "After execution of this cell metric on an ensemble of models is printed, and a picture with visualization of predictions of first 9 time series is saved into file 'n_beats_111.png'. There blue line corresponds to historical data of time series, green line - true values, red line - predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1428, 36) (1428, 18)\n",
      "-------------------------------------\n",
      "2\n",
      "(1428, 36) (1428, 18)\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422688864\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422688248\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422689536\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422690656\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398003581672\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398003582288\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398003581000\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423212144\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423214664\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423211192\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423212480\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419383280\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419384344\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004274232\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004276024\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419656816\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419656704\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419657376\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422719728\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422721296\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422723312\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422741160\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422743848\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422742504\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422743456\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422740824\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422740376\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423190144\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423187960\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423188352\n",
      "--- Evaluating ---\n",
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_2H_G_1_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8365.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5024.0000,  7815.0000,\n",
      "         8196.6000,  7100.0000,  4632.7000,  7533.8000,  5332.0000,  4773.4000,\n",
      "         5039.6000,  5315.5000,  6274.0000,  4494.4000,  4672.0000,  9801.0000,\n",
      "         7145.0000,  3716.0000,  7367.5000,  6490.2000,  5916.0000,  6375.5000,\n",
      "         5914.1000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5050.0000,  6750.0000,  6300.0000,  6300.0000, 24795.0000,\n",
      "        20030.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         6576.4000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  4978.3000,  7731.6000,\n",
      "         6293.1000,  6191.4000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8474.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         6979.7000,  5514.0000,  7528.8300,  6941.7400,  7221.6000,  9329.8000,\n",
      "         8830.8000,  6621.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  8336.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5734.0000,  5733.5000,  5887.5000,  5549.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5533.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 10068.0600,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5184.9000,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  3239.0000,  7755.0000,  9272.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8545.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7584.3000,  5312.0000,  3856.4000,\n",
      "         5644.0000,  7550.0000,  5180.0000,  5690.0000,  7165.0000,  4246.0000,\n",
      "         8620.0000,  4068.0000,  5110.0000,  8003.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6188.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6625.5000,  7401.9000,\n",
      "         8887.0000,  5130.0000,  8330.0000,  6566.0000,  7503.0000,  6230.0000,\n",
      "         5290.0000,  6390.0000,  6090.0000,  4505.0000,  6920.0000,  9662.0000,\n",
      "         4985.0000,  8724.5000,  7659.0000,  8180.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5281.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  7550.0000, 32210.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  4000.0000, 16430.0000,\n",
      "        24840.0000,  8077.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3470.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9200.0000, 11200.0000,  8000.0000,  9640.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "         9480.0000, 10680.0000, 10000.0000, 10640.0000,  9840.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8001.0000,  2301.8000,  7317.2000,\n",
      "        11125.0000,  4093.9000,  7565.7000,  8740.7000,  3246.7000,  3845.5000,\n",
      "         6014.7000,  6257.7000,  5159.9000,  2901.5000,  6990.2000,  2970.6000,\n",
      "         3569.4000,  9423.6000,  3189.3000,  3418.7000,  4168.2000,  6754.5000,\n",
      "         9538.3000,  3874.7000,  6266.2000,  3008.9000,  4187.0000,  3461.1000,\n",
      "         3095.9000,  2269.9000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss 14.83097808039849\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004502312\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004499232\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004498728\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424394032\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424392184\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424391960\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004936040\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004058040\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004057704\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419677856\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406040024\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406037112\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406039632\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406036664\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406038568\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406039464\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406038288\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424597040\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424597152\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419383728\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419383392\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419385128\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422065488\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422066104\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424466304\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424481456\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004093784\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400425427016\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004381904\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004383136\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_2H_G_2_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8365.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5024.0000,  7815.0000,\n",
      "         8196.6000,  7100.0000,  4632.7000,  7533.8000,  5332.0000,  4773.4000,\n",
      "         5039.6000,  5315.5000,  6274.0000,  4494.4000,  4672.0000,  9801.0000,\n",
      "         7145.0000,  3716.0000,  7367.5000,  6490.2000,  5916.0000,  6375.5000,\n",
      "         5914.1000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5050.0000,  6750.0000,  6300.0000,  6300.0000, 24795.0000,\n",
      "        20030.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         6576.4000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  4978.3000,  7731.6000,\n",
      "         6293.1000,  6191.4000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8474.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         6979.7000,  5514.0000,  7528.8300,  6941.7400,  7221.6000,  9329.8000,\n",
      "         8830.8000,  6621.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  8336.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5734.0000,  5733.5000,  5887.5000,  5549.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5533.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 10068.0600,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5184.9000,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  3239.0000,  7755.0000,  9272.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8545.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7584.3000,  5312.0000,  3856.4000,\n",
      "         5644.0000,  7550.0000,  5180.0000,  5690.0000,  7165.0000,  4246.0000,\n",
      "         8620.0000,  4068.0000,  5110.0000,  8003.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6188.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6625.5000,  7401.9000,\n",
      "         8887.0000,  5130.0000,  8330.0000,  6566.0000,  7503.0000,  6230.0000,\n",
      "         5290.0000,  6390.0000,  6090.0000,  4505.0000,  6920.0000,  9662.0000,\n",
      "         4985.0000,  8724.5000,  7659.0000,  8180.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5281.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  7550.0000, 32210.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  4000.0000, 16430.0000,\n",
      "        24840.0000,  8077.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3470.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9200.0000, 11200.0000,  8000.0000,  9640.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "         9480.0000, 10680.0000, 10000.0000, 10640.0000,  9840.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8001.0000,  2301.8000,  7317.2000,\n",
      "        11125.0000,  4093.9000,  7565.7000,  8740.7000,  3246.7000,  3845.5000,\n",
      "         6014.7000,  6257.7000,  5159.9000,  2901.5000,  6990.2000,  2970.6000,\n",
      "         3569.4000,  9423.6000,  3189.3000,  3418.7000,  4168.2000,  6754.5000,\n",
      "         9538.3000,  3874.7000,  6266.2000,  3008.9000,  4187.0000,  3461.1000,\n",
      "         3095.9000,  2269.9000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -3.484521859269419\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398003583632\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398003583240\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423212200\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423211472\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423214160\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423212592\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423214944\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419381600\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419385016\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004275128\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419657208\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419659448\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419657544\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419657040\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422721688\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422723536\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422719840\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422743344\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422740880\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422742224\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422742112\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422741832\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422741720\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419502960\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419503408\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419430128\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419429400\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419427272\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419426824\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419429568\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_2H_G_3_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8365.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5024.0000,  7815.0000,\n",
      "         8196.6000,  7100.0000,  4632.7000,  7533.8000,  5332.0000,  4773.4000,\n",
      "         5039.6000,  5315.5000,  6274.0000,  4494.4000,  4672.0000,  9801.0000,\n",
      "         7145.0000,  3716.0000,  7367.5000,  6490.2000,  5916.0000,  6375.5000,\n",
      "         5914.1000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5050.0000,  6750.0000,  6300.0000,  6300.0000, 24795.0000,\n",
      "        20030.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         6576.4000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  4978.3000,  7731.6000,\n",
      "         6293.1000,  6191.4000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8474.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         6979.7000,  5514.0000,  7528.8300,  6941.7400,  7221.6000,  9329.8000,\n",
      "         8830.8000,  6621.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  8336.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5734.0000,  5733.5000,  5887.5000,  5549.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5533.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 10068.0600,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5184.9000,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  3239.0000,  7755.0000,  9272.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8545.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7584.3000,  5312.0000,  3856.4000,\n",
      "         5644.0000,  7550.0000,  5180.0000,  5690.0000,  7165.0000,  4246.0000,\n",
      "         8620.0000,  4068.0000,  5110.0000,  8003.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6188.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6625.5000,  7401.9000,\n",
      "         8887.0000,  5130.0000,  8330.0000,  6566.0000,  7503.0000,  6230.0000,\n",
      "         5290.0000,  6390.0000,  6090.0000,  4505.0000,  6920.0000,  9662.0000,\n",
      "         4985.0000,  8724.5000,  7659.0000,  8180.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5281.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  7550.0000, 32210.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  4000.0000, 16430.0000,\n",
      "        24840.0000,  8077.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3470.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9200.0000, 11200.0000,  8000.0000,  9640.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "         9480.0000, 10680.0000, 10000.0000, 10640.0000,  9840.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8001.0000,  2301.8000,  7317.2000,\n",
      "        11125.0000,  4093.9000,  7565.7000,  8740.7000,  3246.7000,  3845.5000,\n",
      "         6014.7000,  6257.7000,  5159.9000,  2901.5000,  6990.2000,  2970.6000,\n",
      "         3569.4000,  9423.6000,  3189.3000,  3418.7000,  4168.2000,  6754.5000,\n",
      "         9538.3000,  3874.7000,  6266.2000,  3008.9000,  4187.0000,  3461.1000,\n",
      "         3095.9000,  2269.9000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -6.991135550263742\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004935928\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004059944\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419677016\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419676456\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406037952\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406037000\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406038008\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406040528\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406037392\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400406038120\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424597656\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424598216\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424598720\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419382496\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419384288\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419382048\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422067112\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424468376\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424466360\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424484480\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004093504\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400425427296\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004383248\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004848680\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004847672\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398005014480\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398005013752\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398005012744\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398005011736\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398005010896\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_2H_G_4_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8365.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5024.0000,  7815.0000,\n",
      "         8196.6000,  7100.0000,  4632.7000,  7533.8000,  5332.0000,  4773.4000,\n",
      "         5039.6000,  5315.5000,  6274.0000,  4494.4000,  4672.0000,  9801.0000,\n",
      "         7145.0000,  3716.0000,  7367.5000,  6490.2000,  5916.0000,  6375.5000,\n",
      "         5914.1000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5050.0000,  6750.0000,  6300.0000,  6300.0000, 24795.0000,\n",
      "        20030.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         6576.4000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  4978.3000,  7731.6000,\n",
      "         6293.1000,  6191.4000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8474.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         6979.7000,  5514.0000,  7528.8300,  6941.7400,  7221.6000,  9329.8000,\n",
      "         8830.8000,  6621.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  8336.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5734.0000,  5733.5000,  5887.5000,  5549.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5533.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 10068.0600,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5184.9000,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  3239.0000,  7755.0000,  9272.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8545.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7584.3000,  5312.0000,  3856.4000,\n",
      "         5644.0000,  7550.0000,  5180.0000,  5690.0000,  7165.0000,  4246.0000,\n",
      "         8620.0000,  4068.0000,  5110.0000,  8003.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6188.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6625.5000,  7401.9000,\n",
      "         8887.0000,  5130.0000,  8330.0000,  6566.0000,  7503.0000,  6230.0000,\n",
      "         5290.0000,  6390.0000,  6090.0000,  4505.0000,  6920.0000,  9662.0000,\n",
      "         4985.0000,  8724.5000,  7659.0000,  8180.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5281.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  7550.0000, 32210.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  4000.0000, 16430.0000,\n",
      "        24840.0000,  8077.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3470.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9200.0000, 11200.0000,  8000.0000,  9640.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "         9480.0000, 10680.0000, 10000.0000, 10640.0000,  9840.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8001.0000,  2301.8000,  7317.2000,\n",
      "        11125.0000,  4093.9000,  7565.7000,  8740.7000,  3246.7000,  3845.5000,\n",
      "         6014.7000,  6257.7000,  5159.9000,  2901.5000,  6990.2000,  2970.6000,\n",
      "         3569.4000,  9423.6000,  3189.3000,  3418.7000,  4168.2000,  6754.5000,\n",
      "         9538.3000,  3874.7000,  6266.2000,  3008.9000,  4187.0000,  3461.1000,\n",
      "         3095.9000,  2269.9000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss 15.150625998254938\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423213488\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423211528\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423211864\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400423212648\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419385184\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419383448\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419384680\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004275408\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419657320\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419658048\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419656480\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422722360\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422720736\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422722920\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422721576\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422743848\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422741888\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422740208\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422743512\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400422741608\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419500104\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419500776\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419427216\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419429288\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419429736\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419428224\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400419427328\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424854920\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22400424854136\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=36, forecast_length=18, share_thetas=False) at @22398004850248\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_2H_G_5_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8365.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5024.0000,  7815.0000,\n",
      "         8196.6000,  7100.0000,  4632.7000,  7533.8000,  5332.0000,  4773.4000,\n",
      "         5039.6000,  5315.5000,  6274.0000,  4494.4000,  4672.0000,  9801.0000,\n",
      "         7145.0000,  3716.0000,  7367.5000,  6490.2000,  5916.0000,  6375.5000,\n",
      "         5914.1000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5050.0000,  6750.0000,  6300.0000,  6300.0000, 24795.0000,\n",
      "        20030.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         6576.4000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  4978.3000,  7731.6000,\n",
      "         6293.1000,  6191.4000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8474.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         6979.7000,  5514.0000,  7528.8300,  6941.7400,  7221.6000,  9329.8000,\n",
      "         8830.8000,  6621.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  8336.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5734.0000,  5733.5000,  5887.5000,  5549.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5533.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 10068.0600,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5184.9000,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  3239.0000,  7755.0000,  9272.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8545.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7584.3000,  5312.0000,  3856.4000,\n",
      "         5644.0000,  7550.0000,  5180.0000,  5690.0000,  7165.0000,  4246.0000,\n",
      "         8620.0000,  4068.0000,  5110.0000,  8003.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6188.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6625.5000,  7401.9000,\n",
      "         8887.0000,  5130.0000,  8330.0000,  6566.0000,  7503.0000,  6230.0000,\n",
      "         5290.0000,  6390.0000,  6090.0000,  4505.0000,  6920.0000,  9662.0000,\n",
      "         4985.0000,  8724.5000,  7659.0000,  8180.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5281.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  7550.0000, 32210.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  4000.0000, 16430.0000,\n",
      "        24840.0000,  8077.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3470.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9200.0000, 11200.0000,  8000.0000,  9640.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "         9480.0000, 10680.0000, 10000.0000, 10640.0000,  9840.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8001.0000,  2301.8000,  7317.2000,\n",
      "        11125.0000,  4093.9000,  7565.7000,  8740.7000,  3246.7000,  3845.5000,\n",
      "         6014.7000,  6257.7000,  5159.9000,  2901.5000,  6990.2000,  2970.6000,\n",
      "         3569.4000,  9423.6000,  3189.3000,  3418.7000,  4168.2000,  6754.5000,\n",
      "         9538.3000,  3874.7000,  6266.2000,  3008.9000,  4187.0000,  3461.1000,\n",
      "         3095.9000,  2269.9000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -28.02258306805245\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "3\n",
      "(1428, 54) (1428, 18)\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424483584\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004096864\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004093112\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004382128\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004383136\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406040192\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406037784\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406039520\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406038736\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406037224\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406040080\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406036720\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424597768\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424597992\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419383728\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419385240\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419384120\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422067952\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422065320\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424466304\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005014200\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005013360\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005012408\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005011400\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424857496\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424856488\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424855480\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419607552\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419606992\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004657792\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_3H_G_1_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4666.0000,  7367.5000,  6490.2000,  6040.0000,  6860.1000,\n",
      "         6065.5000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7056.5000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6175.3000,  8344.0000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8514.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         7329.7000,  5949.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9036.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 11091.9300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5382.5200,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8660.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7730.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8890.0000,  4168.0000,  5170.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5190.0000,  8330.0000,  6663.5000,  7695.0000,  6430.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4595.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8260.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5364.2000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8050.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "        10160.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss 15.086088475809522\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004273448\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419656704\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419657376\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419657040\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422722360\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422721408\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422720344\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422722752\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422741216\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422740992\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422740656\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422740264\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422742448\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419500272\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419502904\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419428616\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419427720\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419428448\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419427944\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419429568\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424854192\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424853688\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424708976\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424708024\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419544312\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419542240\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419542072\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419541120\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419543976\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419542688\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_3H_G_2_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4666.0000,  7367.5000,  6490.2000,  6040.0000,  6860.1000,\n",
      "         6065.5000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7056.5000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6175.3000,  8344.0000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8514.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         7329.7000,  5949.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9036.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 11091.9300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5382.5200,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8660.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7730.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8890.0000,  4168.0000,  5170.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5190.0000,  8330.0000,  6663.5000,  7695.0000,  6430.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4595.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8260.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5364.2000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8050.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "        10160.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss 15.54469171755322\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004095576\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400425427744\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004380504\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004380056\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406040192\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406037280\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406036664\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406036608\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406038792\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400406038344\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424597040\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424596872\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424597432\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422068008\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400422066104\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424468376\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005013304\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005012296\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005011288\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005010840\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424857496\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424855592\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424855928\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419608280\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419607160\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397972998072\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397972997176\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424710096\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424706232\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424707128\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_3H_G_3_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4666.0000,  7367.5000,  6490.2000,  6040.0000,  6860.1000,\n",
      "         6065.5000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7056.5000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6175.3000,  8344.0000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8514.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         7329.7000,  5949.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9036.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 11091.9300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5382.5200,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8660.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7730.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8890.0000,  4168.0000,  5170.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5190.0000,  8330.0000,  6663.5000,  7695.0000,  6430.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4595.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8260.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5364.2000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8050.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "        10160.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -57.162503032859775\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424854584\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424854024\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424708080\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424707352\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973029944\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973029104\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397972999416\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004848960\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004849464\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973039088\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973040152\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973040936\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410391384\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410392168\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410393176\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410394184\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410415568\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410416464\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410417528\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410418032\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410569304\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410567456\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410568464\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410569472\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410570256\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410569864\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410567512\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410534800\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410535528\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400410536368\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_3H_G_4_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4666.0000,  7367.5000,  6490.2000,  6040.0000,  6860.1000,\n",
      "         6065.5000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7056.5000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6175.3000,  8344.0000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8514.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         7329.7000,  5949.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9036.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 11091.9300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5382.5200,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8660.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7730.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8890.0000,  4168.0000,  5170.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5190.0000,  8330.0000,  6663.5000,  7695.0000,  6430.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4595.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8260.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5364.2000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8050.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "        10160.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -9.629664137773059\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005013304\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005013528\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005012464\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398005011512\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424855256\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424856600\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424855704\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397972998744\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397972998016\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397972997008\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424710040\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400424706288\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973038192\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973037240\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973032296\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973031288\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22397973030224\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419501560\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400419502456\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398003794776\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398003795504\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398003796568\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398003797576\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004109720\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004110672\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004111736\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22398004112520\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400405954232\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400405951096\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=54, forecast_length=18, share_thetas=False) at @22400405952048\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_3H_G_5_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4666.0000,  7367.5000,  6490.2000,  6040.0000,  6860.1000,\n",
      "         6065.5000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7056.5000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6175.3000,  8344.0000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5574.4200,  4365.2600,  9315.0000,\n",
      "         9662.0000,  5666.8000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400,  8514.0000,  4892.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         7329.7000,  5949.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  6474.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9036.6000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6455.6000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  4850.8000,  5586.4000,  6028.2000,\n",
      "         5268.0000, 10883.5000,  5509.0000,  7288.3500, 11091.9300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5382.5200,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8660.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6578.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7730.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8890.0000,  4168.0000,  5170.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5190.0000,  8330.0000,  6663.5000,  7695.0000,  6430.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4595.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8260.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5364.2000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8050.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  6710.0000,  5960.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5510.0000,  5564.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10000.0000,  9840.0000,  9720.0000, 10640.0000,  9240.0000,  9480.0000,\n",
      "        10160.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss 14.954152284743081\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "4\n",
      "(1428, 72) (1428, 18)\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410567288\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410567176\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410568016\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410569024\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410569976\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410570032\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410567624\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397972999024\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004849800\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004850416\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397973039760\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397973040600\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397973041048\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410392000\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410392840\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410393848\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410394352\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410416408\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410417360\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410418256\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410419152\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423010824\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423012056\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419543136\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419542464\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419544480\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419541288\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419541176\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419542912\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419501672\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_4H_G_1_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6159.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7189.1000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9662.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 10277.0000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8137.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11239.1300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7740.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8900.0000,  4168.0000,  5185.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5260.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4675.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5449.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss 14.625880904165035\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397972997848\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397972998408\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397973038472\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397973037912\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419543360\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398003795224\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398003796232\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398003797240\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398003797856\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004110504\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004111400\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004112240\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004112184\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424981616\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424982288\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424983800\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424983296\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424982344\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424983856\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425109768\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425110776\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425108984\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425110664\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425108312\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425111000\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425108704\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425107976\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425055288\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425055120\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425056800\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_4H_G_2_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6159.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7189.1000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9662.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 10277.0000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8137.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11239.1300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7740.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8900.0000,  4168.0000,  5185.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5260.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4675.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5449.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -3.694178855180458\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397972998744\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004848960\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004849240\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397973039816\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397973039480\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22397973040208\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410390992\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410391720\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410392504\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410393456\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410415512\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410415288\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410416016\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410417080\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410419040\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423012000\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419543248\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419543696\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419544424\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419541792\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419542744\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419541568\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419544312\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400406300824\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400806695264\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424984192\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424982568\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410537824\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410536424\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410534128\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_4H_G_3_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6159.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7189.1000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9662.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 10277.0000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8137.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11239.1300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7740.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8900.0000,  4168.0000,  5185.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5260.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4675.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5449.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -29.110294110886592\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398003794552\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398003796232\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398003797240\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398003797856\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004110504\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004111400\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004112240\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004112184\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424981784\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424982288\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424983800\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424983296\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424982344\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424983856\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425109432\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425110776\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425108984\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425110664\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425108312\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425111000\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425108704\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400425107976\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419755736\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419757528\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419757696\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419754112\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424946992\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004095240\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004094232\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22398004095016\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_4H_G_4_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6159.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7189.1000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9662.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 10277.0000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8137.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11239.1300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7740.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8900.0000,  4168.0000,  5185.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5260.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4675.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5449.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -3.512691909181194\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410391384\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410391160\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410391832\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410392560\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410415176\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410418928\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410416184\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410417192\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400410418536\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423011440\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400807049928\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424983016\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400424981000\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423190424\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423188576\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423188520\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423186952\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423189416\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423188184\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400423187288\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419755512\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419503408\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419502176\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419503016\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419501336\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419396352\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419397248\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419395064\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419396688\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=72, forecast_length=18, share_thetas=False) at @22400419395792\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_4H_G_5_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5991.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6159.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  8700.0000,\n",
      "         7189.1000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9662.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 10277.0000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8137.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 13836.0000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11239.1300,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5413.3800,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5753.0000,  7740.0000,  5310.0000,  5720.0000,  7300.0000,  4262.0000,\n",
      "         8900.0000,  4168.0000,  5185.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  5260.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5430.0000,  6435.0000,  6090.0000,  4675.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5449.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  6720.7600,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -8.397852289276184\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "5\n",
      "(1428, 90) (1428, 18)\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22398004675360\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22398004096192\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22398004093504\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22398004095744\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419607384\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419607328\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425109320\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425108144\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425108760\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425111448\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425108592\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425110104\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425107864\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425111336\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419757864\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419757472\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419757920\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419754448\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423186672\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425057360\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425057528\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425057920\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425056408\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425055064\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425054560\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425055176\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425020944\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425017696\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425020664\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425018704\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_5H_G_1_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5999.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6363.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         7965.0000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5760.0000,  7740.0000,  5310.0000,  5720.0000,  7355.0000,  4450.0000,\n",
      "         9410.0000,  4168.0000,  5260.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  6760.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5440.0000,  6700.0000,  6090.0000,  4735.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5465.4000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -123.81256662664612\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400410415960\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400410415288\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400410416016\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400410417080\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423012224\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423012000\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400405953896\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423190088\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423186896\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423189864\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423186616\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423187344\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423188744\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425057192\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419756352\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419500664\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419501728\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419503520\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422742728\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422743288\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422741720\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422742168\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422740376\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422740824\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422743456\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419610408\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419609624\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419608448\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419608168\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406300432\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_5H_G_2_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5999.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6363.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         7965.0000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5760.0000,  7740.0000,  5310.0000,  5720.0000,  7355.0000,  4450.0000,\n",
      "         9410.0000,  4168.0000,  5260.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  6760.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5440.0000,  6700.0000,  6090.0000,  4735.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5465.4000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -26.12115366303394\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419607160\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419607328\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425109712\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425111112\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425110216\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425109824\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425108928\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425110720\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425107640\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425109376\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419755792\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419754392\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419754280\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419756128\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419756296\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425057360\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425057528\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425057920\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425056408\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425055064\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425054560\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425055176\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425054392\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406038008\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406040248\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406036776\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406038960\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422801480\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422803552\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422804336\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_5H_G_3_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5999.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6363.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         7965.0000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5760.0000,  7740.0000,  5310.0000,  5720.0000,  7355.0000,  4450.0000,\n",
      "         9410.0000,  4168.0000,  5260.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  6760.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5440.0000,  6700.0000,  6090.0000,  4735.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5465.4000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -36.47047688829748\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400807049928\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423187008\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423188576\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423188520\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423186952\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423189416\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423188184\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400423187232\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419755848\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419503408\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419502288\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419500776\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422744016\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422743736\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422743120\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422742672\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422743680\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422740936\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400422743848\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419610408\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419607272\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419608896\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419610352\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400424707912\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400424708360\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400424707184\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400424706456\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406039296\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406037896\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425021112\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_5H_G_4_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5999.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6363.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         7965.0000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5760.0000,  7740.0000,  5310.0000,  5720.0000,  7355.0000,  4450.0000,\n",
      "         9410.0000,  4168.0000,  5260.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  6760.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5440.0000,  6700.0000,  6090.0000,  4735.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5465.4000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -1.2854714427696439\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425109712\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425108424\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425108200\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425109264\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425107696\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425110944\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425109152\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425107584\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419755680\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419756016\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419757248\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400419757696\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400410536816\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425057136\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425056296\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425057696\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425056520\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425056632\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425054336\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425055344\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406038792\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406036608\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406036664\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406037280\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406037840\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406301608\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406302056\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406300992\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400406301440\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=90, forecast_length=18, share_thetas=False) at @22400425018872\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_5H_G_5_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  5999.0000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  4836.0000,  7367.5000,  6490.2000,  6363.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         6300.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         7965.0000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6690.0000,  4885.5000,  9135.0000,  7607.1000,  5312.0000,  3898.0000,\n",
      "         5760.0000,  7740.0000,  5310.0000,  5720.0000,  7355.0000,  4450.0000,\n",
      "         9410.0000,  4168.0000,  5260.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6681.5000,  7401.9000,\n",
      "         8933.0000,  6760.0000,  8330.0000,  6663.5000,  7695.0000,  6450.0000,\n",
      "         5440.0000,  6700.0000,  6090.0000,  4735.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5465.4000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -10.518343842729415\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "6\n",
      "(1428, 108) (1428, 18)\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424709144\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424708360\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424707184\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424706456\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424709368\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419754560\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419502176\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419501224\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419501336\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422742504\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422742896\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422742728\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422743960\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422740096\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422742784\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422743624\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406039800\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406036888\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422800800\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422799176\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406301272\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406300432\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410536032\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410535248\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410537376\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410536144\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410537880\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410537712\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410501808\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410502816\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_6H_G_1_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         7350.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6788.0000,  4943.5000,  9135.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  6950.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -66.95760944393199\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419754392\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419754336\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419755960\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419754840\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400425057416\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400425058200\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400425058088\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400425056128\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400425057024\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400425055232\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400425054616\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400425055288\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406300544\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406302560\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406300096\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406300488\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423028160\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423030400\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423028888\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423030568\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422799904\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422797944\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422798952\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422800352\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422799624\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422798896\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419395120\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422805232\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422804056\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422802712\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_6H_G_2_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         7350.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6788.0000,  4943.5000,  9135.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  6950.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -31.366489550639542\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419755680\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419500440\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419500272\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419502792\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419500552\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422743400\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422743344\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422743288\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422740768\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422742448\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422740264\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422743680\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406037896\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406038344\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422798112\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406301272\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406302448\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410534072\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410537264\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410534128\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410536424\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410537600\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410536872\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424855704\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424856600\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424853576\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424854472\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423026928\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423029168\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400425019432\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_6H_G_3_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         7350.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6788.0000,  4943.5000,  9135.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  6950.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -1.2123531602037543\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406299256\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406302560\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406300096\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406300488\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423028160\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423030400\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423028888\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423030568\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423030512\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422797944\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422798952\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422800352\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422799624\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422798896\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419502008\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419501560\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419501168\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410535864\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410504216\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410503320\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406038400\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406038960\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406036776\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406040248\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406038008\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419639536\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22398003520232\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22398003520960\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22398003521968\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22398003521408\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_6H_G_4_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         7350.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6788.0000,  4943.5000,  9135.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  6950.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss 14.87092087172317\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422742000\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422743344\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422743288\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422740768\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422742448\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422740264\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422743680\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406037896\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406038344\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400422798112\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406301720\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400406298808\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410536032\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410534520\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410534016\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410535024\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410537320\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400410537040\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424854920\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424856208\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424857384\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400424854640\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423026872\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423027040\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400423028104\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419591952\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419591280\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419593128\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419591728\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=108, forecast_length=18, share_thetas=False) at @22400419590272\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_6H_G_5_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         7350.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9726.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  5080.5000,\n",
      "         6788.0000,  4943.5000,  9135.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  6950.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 37610.0000,  6084.0000,  8100.0000,\n",
      "        13540.0000,  8174.5000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         5980.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -2.4290129159735647\n",
      "\n",
      "\n",
      "\n",
      "-------------------------------------\n",
      "7\n",
      "(1428, 126) (1428, 18)\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419639424\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422797720\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422800072\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422799568\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422798672\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422800744\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410537208\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410535192\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410503544\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400406037280\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400406036664\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400406038792\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400406038400\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400406038736\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400406037224\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410417136\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410416464\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410416632\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410418984\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410418312\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410416912\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419394336\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422803664\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422805008\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422801480\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422804448\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422802600\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422801592\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400405953112\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400405952216\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_7H_G_1_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         8000.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9808.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  6258.5000,\n",
      "         7004.0000,  5772.5000, 11670.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  7040.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 86730.0000,  6222.0000,  9916.0000,\n",
      "        13540.0000,  9694.0000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         6930.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -2829.76951057917\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422798504\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410534072\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410537264\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410534128\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410536424\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410537600\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410534856\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400424855704\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400424856600\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400424853576\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400424854472\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419591952\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419590832\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419594136\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419593800\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419593408\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419541232\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419541120\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419543976\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419396240\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419395400\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419396072\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419397360\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419396912\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419393664\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419394112\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398013448992\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419641664\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419642168\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419642448\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_7H_G_2_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         8000.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9808.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  6258.5000,\n",
      "         7004.0000,  5772.5000, 11670.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  7040.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 86730.0000,  6222.0000,  9916.0000,\n",
      "        13540.0000,  9694.0000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         6930.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -17.649183976119254\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410533960\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410501192\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410446424\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410415680\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410417584\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410415344\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410417192\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410416184\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410415568\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419594080\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422804896\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422805400\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422802152\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422802824\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422803328\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422805344\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422801984\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398004111512\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973037352\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973039312\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973037128\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973038584\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973039928\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973039256\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973039368\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419542968\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419543472\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419543584\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419542688\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398003522360\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_7H_G_3_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         8000.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9808.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  6258.5000,\n",
      "         7004.0000,  5772.5000, 11670.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  7040.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 86730.0000,  6222.0000,  9916.0000,\n",
      "        13540.0000,  9694.0000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         6930.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -5.456369281266992\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400424856152\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400424854584\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400424854024\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400424853744\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419591952\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419593128\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419591728\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419590272\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419592512\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419542576\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419543864\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419544928\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419394952\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419396688\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419395064\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419397248\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419396352\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419397416\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419395008\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419805168\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400807049816\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400423011496\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400423012280\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400423013512\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400423012336\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398004096136\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398004094792\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398004123632\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398004125368\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398004124024\n",
      "--- Evaluating ---\n",
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_7H_G_4_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         8000.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9808.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  6258.5000,\n",
      "         7004.0000,  5772.5000, 11670.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  7040.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 86730.0000,  6222.0000,  9916.0000,\n",
      "        13540.0000,  9694.0000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         6930.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss 15.781096978021331\n",
      "\n",
      "\n",
      "\n",
      "--- Model ---\n",
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410444408\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410417248\n",
      "| --  Stack Generic (#2) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410415232\n",
      "| --  Stack Generic (#3) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410417472\n",
      "| --  Stack Generic (#4) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410418704\n",
      "| --  Stack Generic (#5) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410417080\n",
      "| --  Stack Generic (#6) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400410416016\n",
      "| --  Stack Generic (#7) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419397472\n",
      "| --  Stack Generic (#8) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422804280\n",
      "| --  Stack Generic (#9) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422801816\n",
      "| --  Stack Generic (#10) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422805064\n",
      "| --  Stack Generic (#11) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422803944\n",
      "| --  Stack Generic (#12) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422803440\n",
      "| --  Stack Generic (#13) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422803048\n",
      "| --  Stack Generic (#14) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422803160\n",
      "| --  Stack Generic (#15) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398004110168\n",
      "| --  Stack Generic (#16) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973039424\n",
      "| --  Stack Generic (#17) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973040880\n",
      "| --  Stack Generic (#18) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973037464\n",
      "| --  Stack Generic (#19) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973039648\n",
      "| --  Stack Generic (#20) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973040824\n",
      "| --  Stack Generic (#21) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973040152\n",
      "| --  Stack Generic (#22) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22397973039816\n",
      "| --  Stack Generic (#23) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419544984\n",
      "| --  Stack Generic (#24) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419542520\n",
      "| --  Stack Generic (#25) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419543752\n",
      "| --  Stack Generic (#26) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400419543920\n",
      "| --  Stack Generic (#27) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22398004904736\n",
      "| --  Stack Generic (#28) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400424743488\n",
      "| --  Stack Generic (#29) (share_weights_in_stack=True)\n",
      "     | -- GenericBlock(units=512, thetas_dim=4, backcast_length=126, forecast_length=18, share_thetas=False) at @22400422824928\n",
      "--- Evaluating ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restored checkpoint from ./m4_checkpoints_monthly/month_share_7H_G_5_smape.th.\n",
      "tensor([9000.0000, 7440.0000, 8760.0000,  ..., 8878.0000, 6105.0000,\n",
      "        5982.6000], dtype=torch.float64)\n",
      "torch.Size([1024])\n",
      "tensor([ 9350.8000,  8063.0000,  5715.9000,  9131.4000,  5446.5000,  7850.5000,\n",
      "         8280.5000,  7100.0000,  4632.7000,  7533.8000,  6775.5000,  4773.4000,\n",
      "         5544.2000,  6149.5000,  6618.5000,  4702.9000,  4672.0000,  9801.0000,\n",
      "         7450.0000,  5096.0000,  7367.5000,  6490.2000,  6736.0000,  6884.5000,\n",
      "         6569.2000,  9143.0000,  7509.0000,  5930.0000,  7360.0000,  9245.0000,\n",
      "         6970.0000, 15757.6000,  9155.5000,  5180.0000,  6700.0000,  5728.0000,\n",
      "         5775.0000,  7250.0000,  8600.0000,  7100.0000,  6850.0000,  6450.0000,\n",
      "         7200.0000,  7300.0000,  8550.0000,  7300.0000,  6600.0000, 15250.0000,\n",
      "        10080.0000,  5550.0000,  6750.0000,  6300.0000,  6300.0000, 33350.0000,\n",
      "        29130.0000,  6400.0000,  6100.0000,  5800.0000,  6950.0000,  8412.0000,\n",
      "         8075.0000,  5739.5000,  5380.0000,  6669.5000,  8842.0000, 18784.5000,\n",
      "        12470.0000, 30150.0000,  6222.1000,  6515.0000,  8965.0000,  8490.0000,\n",
      "         7750.0000, 10980.0000,  7840.0000,  6500.0000,  7400.0000,  6000.0000,\n",
      "         7550.0000,  7850.0000, 21470.0000,  8400.0000,  8650.0000,  7800.0000,\n",
      "         6600.0000,  6950.0000,  7870.0000,  8035.0000,  5615.0000, 25705.0000,\n",
      "         8000.0000,  8653.4000,  6790.0000, 10950.0000,  7428.2000,  9570.0000,\n",
      "         8206.7000,  5708.6500,  4240.3300, 11762.1500,  6516.3900,  7682.8500,\n",
      "         7061.2200,  5787.8800,  5643.0600,  7061.2200,  6571.3000,  9621.4000,\n",
      "         6374.6000,  6269.9000,  8672.0000,  5988.6000,  4612.3800,  9315.0000,\n",
      "         9896.0000,  6932.4000, 10331.8000,  7983.1400,  7625.8000, 10720.1900,\n",
      "         6505.0400, 11060.5000,  5690.4000,  5866.1400,  6306.6600,  7798.5600,\n",
      "         8451.6000,  6129.0000,  7528.8300,  6941.7400,  7251.3500,  9329.8000,\n",
      "         9760.6000,  6789.4000,  9714.0000,  8873.5800,  7706.2800,  7034.9100,\n",
      "         7420.6600,  8813.4300,  7469.4000,  6998.8500, 14038.0000,  6559.0500,\n",
      "         7967.4700,  8966.7700,  8422.8000, 15553.6000,  7645.0000,  8754.0000,\n",
      "         5946.7000,  9985.8000,  6980.0000,  8078.0000,  9808.2000,  4855.0000,\n",
      "         6997.8000,  6396.0000,  5770.0000,  5733.5000,  5887.5000,  5565.0000,\n",
      "         9761.0000,  6978.8000,  8406.2000,  5028.6000,  5648.0000,  6450.0000,\n",
      "         3523.8000,  5573.0000, 13110.0000, 20781.0000, 16818.0000, 13910.0000,\n",
      "        15939.5000, 15300.0000, 21070.0000, 15216.0000, 27349.5000, 10928.0000,\n",
      "         8834.0000,  8415.0000,  9540.0000,  7710.0000,  5067.5400,  3586.6800,\n",
      "         6753.5600,  4641.0000,  7313.3500,  8358.6000,  9867.4000,  6733.4000,\n",
      "        12656.6000,  7685.0000,  7132.4000,  6702.0000,  7236.0000,  6523.5000,\n",
      "         7744.0000,  8350.0000, 11503.5000,  5732.4000,  4157.4000,  3618.4000,\n",
      "         6320.5000,  7238.5000,  6780.1000,  5166.9000,  5586.4000,  6028.2000,\n",
      "         6095.0000, 10883.5000,  5509.0000,  7288.3500, 11937.3400,  7298.0000,\n",
      "         3890.0000,  5839.5000,  5465.3900,  4589.8300,  9668.5000,  5413.2900,\n",
      "         7452.8500,  6946.1400,  9723.9100,  7080.0000,  7058.0000, 10796.0000,\n",
      "         9850.0000, 10055.0000,  6875.0000,  5668.0000,  7755.0000, 10810.0000,\n",
      "         5206.0000,  4591.3000,  7669.4000, 10880.5000, 10586.0000,  6390.0000,\n",
      "        19875.0000,  6558.4000,  8775.0000,  6480.0000,  5997.7000,  6258.5000,\n",
      "         7004.0000,  5772.5000, 11670.0000,  7607.1000,  5312.0000,  3899.6000,\n",
      "         5808.0000,  7740.0000,  5310.0000,  5720.0000,  7410.0000,  4514.0000,\n",
      "         9520.0000,  4168.0000,  5275.0000,  8004.0000,  8385.0000,  8566.2000,\n",
      "         5818.0000,  6210.0000,  7869.6000,  6728.0000,  8774.1000,  9364.5000,\n",
      "         6694.0000,  8872.0000,  5668.0000,  7480.5000,  6760.0000,  7401.9000,\n",
      "         8933.0000,  7040.0000,  8330.0000,  6684.5000,  7795.0000,  6450.0000,\n",
      "         5485.0000,  6860.0000,  6090.0000,  5140.0000,  6980.0000,  9662.0000,\n",
      "         5003.0000,  8724.5000,  7659.0000,  8280.0000, 10200.5000,  8332.5000,\n",
      "         6180.0000,  7356.0000,  5540.8000,  7364.0000,  6490.4000,  5567.8000,\n",
      "         4745.5000,  5047.1000,  4426.8000,  5342.0000,  4396.7000,  4197.2000,\n",
      "         7862.6000,  6903.6000,  8100.0000, 86730.0000,  6222.0000,  9916.0000,\n",
      "        13540.0000,  9694.0000,  8780.0000,  7420.0000,  7405.0000,  8244.5000,\n",
      "         6120.0000,  8860.0000,  9564.5000,  7306.5000,  5200.0000, 16430.0000,\n",
      "        26120.0000,  8270.0000, 37211.0000,  9611.4000,  8330.0000,  8468.0000,\n",
      "         8569.0000,  9464.3000, 14990.0000,  7300.0000,  8600.0000,  8500.0000,\n",
      "         7350.0000,  5800.0000,  6500.0000, 10100.0000, 10900.0000,  6150.0000,\n",
      "         6930.0000,  6610.0000,  9330.0000,  6470.0000,  3760.0000,  6589.1500,\n",
      "         6229.7500, 10040.0000,  5795.6500,  5635.0000,  5660.0000,  6320.0000,\n",
      "         5774.0000,  9600.0000, 11200.0000, 10400.0000, 10800.0000, 10240.0000,\n",
      "        10200.0000, 10040.0000,  9720.0000, 10640.0000,  9960.0000,  9480.0000,\n",
      "        10680.0000, 10680.0000, 10000.0000, 10760.0000, 10440.0000, 10320.0000,\n",
      "        10600.0000, 10480.0000, 10920.0000,  8776.0000,  2384.6000,  7317.2000,\n",
      "        11855.2000,  4280.8000,  7565.7000,  8789.0000,  3552.4000,  4166.1000,\n",
      "         6407.6000,  6257.7000,  7022.1000,  3420.4000,  7465.9000,  3210.6000,\n",
      "         4425.2000,  9423.6000,  3694.1000,  3498.2000,  5057.9000,  7402.2000,\n",
      "        10324.0000,  3874.7000,  6266.2000,  3301.9000,  4960.9000,  4142.8000,\n",
      "         3095.9000,  2622.4000], dtype=torch.float64)\n",
      "torch.Size([404])\n",
      "Mean loss -4.5972296297509185\n",
      "\n",
      "\n",
      "\n",
      "(1428, 36) (1428, 18)\n",
      "TOTAL SMAPE LOSS: 13.964243871823376\n",
      "Saved image to n_beats_111.png.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_type = 'monthly'\n",
    "train_dataset = 'm4'\n",
    "test_dataset = 'm3'\n",
    "\n",
    "# choosing parameters according to given frequency\n",
    "if data_type == 'yearly':\n",
    "    model_type = 'yearly'\n",
    "    forecast_length = 6\n",
    "elif data_type == 'quarterly':\n",
    "    model_type = 'quarterly'\n",
    "    forecast_length = 8\n",
    "elif data_type == 'monthly':\n",
    "    model_type = 'monthly'\n",
    "    forecast_length = 18\n",
    "elif data_type == 'weekly':\n",
    "    model_type = 'weekly'\n",
    "    forecast_length = 13\n",
    "elif data_type == 'daily':\n",
    "    model_type = 'daily'\n",
    "    forecast_length = 14\n",
    "elif data_type == 'other':\n",
    "    model_type = 'quarterly'\n",
    "    forecast_length = 8\n",
    "else: # data_type == 'hourly'\n",
    "    if train_dataset == 'fred':\n",
    "        model_type = 'monthly'\n",
    "    else:\n",
    "        model_type = 'hourly'\n",
    "    forecast_length = 48\n",
    "\n",
    "# choosing approprite function to load dataset and losses\n",
    "if test_dataset == 'm4':\n",
    "    data_test_loader_func = get_m4_data_testing\n",
    "    numpy_loss_func = smape_loss_numpy\n",
    "    loss_func = smape_loss\n",
    "elif test_dataset == 'm3':\n",
    "    data_test_loader_func = get_m3_data_testing\n",
    "    numpy_loss_func = smape_loss_m3_numpy\n",
    "    loss_func = smape_loss_m3\n",
    "elif test_dataset == 'fred':\n",
    "    data_test_loader_func = get_fred_data_testing\n",
    "    numpy_loss_func = smape_loss_numpy\n",
    "    loss_func = smape_loss \n",
    "elif test_dataset == 'tourism':\n",
    "    data_test_loader_func = get_tourism_data_testing\n",
    "    numpy_loss_func = mape_loss_numpy\n",
    "    loss_func = mape_loss\n",
    "elif test_dataset == 'electricity':\n",
    "    data_test_loader_func = get_electricity_data_testing\n",
    "    numpy_loss_func = nd_loss_numpy\n",
    "    loss_func = nd_loss\n",
    "elif test_dataset == 'traffic':\n",
    "    data_test_loader_func = get_traffic_data_testing\n",
    "    numpy_loss_func = nd_loss_numpy\n",
    "    loss_func = nd_loss\n",
    "    \n",
    "# if dataset has negative values\n",
    "if test_dataset == 'fred':\n",
    "    has_neg_values = True\n",
    "else:\n",
    "    has_neg_values = False\n",
    "    \n",
    "\n",
    "folder = './{}_checkpoints_{}/'.format(train_dataset, model_type)\n",
    "\n",
    "preds_filename = Path('./predictions/{}_on_{}_{}.npy'.format(train_dataset, \\\n",
    "                                                          test_dataset, data_type))\n",
    "\n",
    "# remove previous predictions if any\n",
    "if os.path.exists(preds_filename):\n",
    "    os.remove(preds_filename)\n",
    "\n",
    "file = open(preds_filename, 'ab')\n",
    "\n",
    "num_rand_inits = 5\n",
    "\n",
    "device = torch.device('cpu')\n",
    "batch_size = 1024\n",
    "\n",
    "x, y = data_test_loader_func(2 * forecast_length, forecast_length, data_type)\n",
    "    \n",
    "if test_dataset == 'fred':\n",
    "    main_gens = [batcher(x[0], y, batch_size=batch_size, infinite=False)]\n",
    "else:\n",
    "    main_gens = [batcher(x, y, batch_size=batch_size, infinite=False)]\n",
    "\n",
    "forecast_global = []\n",
    "\n",
    "for i in range(2, 8):\n",
    "    print('-------------------------------------')\n",
    "    print(i)\n",
    "    \n",
    "    backcast_length = i * forecast_length\n",
    "    \n",
    "    x, y = data_test_loader_func(backcast_length, forecast_length, data_type)\n",
    "    \n",
    "    if test_dataset == 'fred':\n",
    "        # scaling data for fred (contains negative elements)\n",
    "        x_scaled = x[0].copy()\n",
    "        max_consts = np.empty(x_scaled.shape[0])\n",
    "        min_consts = np.empty(x_scaled.shape[0])\n",
    "        x_start_indexes = x[1]\n",
    "        for j in range(x_scaled.shape[0]):\n",
    "            ts_nonzero = x_scaled[j, x_start_indexes[j] :]\n",
    "            max_consts[j] = ts_nonzero.max()\n",
    "            min_consts[j] = ts_nonzero.min()\n",
    "            x_scaled[j, -len(ts_nonzero):] = (ts_nonzero - min_consts[j]) / \\\n",
    "                                                 (max_consts[j] - min_consts[j])\n",
    "            \n",
    "        data_gen = batcher(x_scaled, torch.tensor(np.vstack((max_consts, min_consts)).T), \n",
    "                       batch_size=batch_size, infinite=False)\n",
    "            \n",
    "    else:\n",
    "        max_consts = x.max(axis=1)\n",
    "        x_scaled = x.copy()\n",
    "        for j in range(x_scaled.shape[1]):\n",
    "            x_scaled[:, j] /= max_consts\n",
    "            \n",
    "        data_gen = batcher(x_scaled, torch.tensor(max_consts), \n",
    "                       batch_size=batch_size, infinite=False)\n",
    "        \n",
    "    data_gens = list(itertools.tee(data_gen, num_rand_inits))\n",
    "    main_gens = list(itertools.tee(main_gens[-1], num_rand_inits + 1))\n",
    "    \n",
    "    for ind in range(1, num_rand_inits + 1):\n",
    "    \n",
    "        # use interpolated data\n",
    "        if train_dataset == 'fred' and (test_dataset == 'traffic' \\\n",
    "                                        or test_dataset == 'electricity'):\n",
    "            checkpoint_name = '{}{}_share_{}H_G_{}_smape_interpolation.th'.\\\n",
    "                            format(folder, model_type[:-2], i, ind)\n",
    "        else:\n",
    "            checkpoint_name = '{}{}_share_{}H_G_{}_smape.th'.\\\n",
    "                                format(folder, model_type[:-2], i, ind)\n",
    "\n",
    "        print('--- Model ---')\n",
    "        n_stacks = 30\n",
    "        net = NBeatsNet(device=device,\n",
    "                        stack_types=[NBeatsNet.GENERIC_BLOCK] * n_stacks,\n",
    "                        forecast_length=forecast_length,\n",
    "                        thetas_dims=[4] * n_stacks,\n",
    "                        nb_blocks_per_stack=1,\n",
    "                        backcast_length=backcast_length,\n",
    "                        hidden_layer_units=512,\n",
    "                        share_weights_in_stack=True\n",
    "                        )\n",
    "        get_predictions(net, data_gens[ind - 1], main_gens[ind - 1], device, loss_func, \\\n",
    "                        checkpoint_name, forecast_length, file, has_neg_values)\n",
    "        \n",
    "        print('\\n\\n')\n",
    "        \n",
    "file.close()\n",
    "\n",
    "# ensemble predictions\n",
    "shape = (num_rand_inits * 6, y.shape[0], y.shape[1])\n",
    "fp = np.memmap(preds_filename, dtype=np.float64, mode='r', shape=shape)\n",
    "\n",
    "final_results = np.zeros(y.shape)\n",
    "for i in range(shape[1]):\n",
    "    final_results[i] = np.median(fp[:, i, :], axis=0)\n",
    "\n",
    "x, y = data_test_loader_func(2 * forecast_length, forecast_length, data_type)\n",
    "\n",
    "print('TOTAL LOSS:', numpy_loss_func(final_results, y))\n",
    "\n",
    "# plot predictions\n",
    "if test_dataset == 'fred':\n",
    "    plot_model_forecast(x[0], y, final_results, x[0].shape[1], y.shape[1], 111)\n",
    "else:\n",
    "    plot_model_forecast(x, y, final_results, x.shape[1], y.shape[1], 111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS M3\n",
    "\n",
    "- yearly - 15.94428063346042\n",
    "- quarterly - 9.147552690437868\n",
    "- monthly - 13.964243871823376\n",
    "- others - 4.715946136495024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS TOURISM M4 net\n",
    "\n",
    "- yearly - 25.234135734209012\n",
    "- quarterly - 17.639429805711472\n",
    "- monthly - 25.014227059301113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results TOURISM Fred net\n",
    "\n",
    "- yearly 26.847688343832278\n",
    "- quarterly 17.28444869727248\n",
    "- monthly 25.695648729991333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS TRAFFIC M4 net\n",
    "\n",
    "- hourly - 0.2443968848233911"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results FRED on traffic and electricity\n",
    "\n",
    "- traffic hourly trained on iterpolated monthly - 0.23013895820344463\n",
    "- electricity hourly trained on interpolated monthly- 0.21938431714041037"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS Electricity M4 net\n",
    "\n",
    "- hourly - 0.13474562335339776"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results M3 Fred net\n",
    "\n",
    "- yearly - 16.309872060049997\n",
    "- quarterly - 10.197710653585455\n",
    "- monthly - 15.727853859605748\n",
    "- other 9.440075011064183"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results M4 Fred net\n",
    "\n",
    "- yearly - 13.743889522675387\n",
    "- quarterly - 10.973342198684769\n",
    "- monthly - 14.763698017364712"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results Fred M4 net\n",
    "\n",
    "- yearly - 21.1807508712548\n",
    "- quarterly - 23.38358699862408\n",
    "- monthly - 16.756561466766794\n",
    "- weekly - 28.342975713278936\n",
    "- daily - 34.29391050641504"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RESULTS M4 tourism\n",
    "\n",
    "- yearly - 25.234135734209012\n",
    "- quarterly - 17.639429805711472\n",
    "- monthly - 25.014227059301113"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to get data using shifted window (or moving average)\n",
    "To predict more data than an N-BEATS model can predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_electricity_data_testing_MA(backcast_length, forecast_length, \\\n",
    "                                    data_type, is_fred=False):\n",
    "\n",
    "    if is_fred:\n",
    "        forecast_length *= 9\n",
    "        forecast_length += 6\n",
    "    if not is_fred:\n",
    "        forecast_length *= 3.5\n",
    "    forecast_length = int(forecast_length)\n",
    "    x = np.array([]).reshape(0, backcast_length)\n",
    "    y = np.array([]).reshape(0, forecast_length)\n",
    "    \n",
    "    # read train and test\n",
    "    x_ts_train = np.load('./data/electricity.npy')\n",
    "    \n",
    "    for i in range(x_ts_train.shape[1]):\n",
    "        \n",
    "        time_series_cleaned = np.trim_zeros(x_ts_train[:, i], 'fb')\n",
    "        \n",
    "        time_series_cleaned_forlearning_x = np.zeros((1, backcast_length))\n",
    "        time_series_cleaned_forlearning_y = np.zeros((1, forecast_length))\n",
    "\n",
    "        nonzero_input = time_series_cleaned\\\n",
    "                [-(backcast_length + forecast_length): -forecast_length]\n",
    "        time_series_cleaned_forlearning_x[0, -len(nonzero_input):] = nonzero_input\n",
    "        nonzero_output = time_series_cleaned[-forecast_length :]\n",
    "        time_series_cleaned_forlearning_y[0, : len(nonzero_output)] = nonzero_output\n",
    "\n",
    "        x = np.vstack((x, time_series_cleaned_forlearning_x))\n",
    "        y = np.vstack((y, time_series_cleaned_forlearning_y))\n",
    "\n",
    "    x = np.vstack([x[:346], x[347:]]) # remove one strange (zeros) time series\n",
    "    y = np.vstack([y[:346], y[347:]])\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "def get_traffic_data_testing_MA(backcast_length, forecast_length, data_type, \\\n",
    "                                is_fred=False):\n",
    "    \n",
    "    if is_fred:\n",
    "        forecast_length *= 9\n",
    "        forecast_length += 6\n",
    "    else:\n",
    "        forecast_length *= 3.5\n",
    "    forecast_length = int(forecast_length)\n",
    "    x = np.array([]).reshape(0, backcast_length)\n",
    "    y = np.array([]).reshape(0, forecast_length)\n",
    "    \n",
    "    # read train and test\n",
    "    x_ts_train = np.load('./data/traffic.npy')\n",
    "    print()\n",
    "    print(\"TRAFFIC SHAPE\", x_ts_train.shape)\n",
    "    print()\n",
    "    for i in range(x_ts_train.shape[1]):\n",
    "        \n",
    "        time_series_cleaned = x_ts_train[:, i]\n",
    "        time_series_cleaned = time_series_cleaned[time_series_cleaned > 0]\n",
    "        \n",
    "        time_series_cleaned_forlearning_x = np.zeros((1, backcast_length))\n",
    "        time_series_cleaned_forlearning_y = np.zeros((1, forecast_length))\n",
    "\n",
    "        nonzero_input = time_series_cleaned\\\n",
    "                [-(backcast_length + forecast_length): -forecast_length]\n",
    "        time_series_cleaned_forlearning_x[0, -len(nonzero_input):] = nonzero_input\n",
    "        nonzero_output = time_series_cleaned[-forecast_length :]\n",
    "        time_series_cleaned_forlearning_y[0, : len(nonzero_output)] = nonzero_output\n",
    "\n",
    "        x = np.vstack((x, time_series_cleaned_forlearning_x))\n",
    "        y = np.vstack((y, time_series_cleaned_forlearning_y))\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def get_tourism_data_testing_MA(backcast_length, forecast_length, data_type):\n",
    "\n",
    "    # extra fields with metainformation in some frequencies\n",
    "    if data_type == 'yearly':\n",
    "        extra_length = 2\n",
    "    else:\n",
    "        extra_length = 3\n",
    "        \n",
    "    # new\n",
    "    forecast_length += 6\n",
    "    \n",
    "    # read train\n",
    "    data_tour = pd.read_csv('./data/tourism/{}-train.csv'.format(data_type))\n",
    "    lengths = data_tour.iloc[0].astype(int).values\n",
    "    data = data_tour.values[extra_length:, :]\n",
    "    \n",
    "    x_ts = []\n",
    "    for i in range(data.shape[1]):\n",
    "        line = data[:lengths[i], i]\n",
    "        x_ts.append(line)\n",
    "\n",
    "    x_ts_train = np.array(x_ts)\n",
    "    \n",
    "    # read test\n",
    "    data_tour = pd.read_csv('./data/tourism/{}-test.csv'.format(data_type))\n",
    "    lengths = data_tour.iloc[0].astype(int).values\n",
    "    data = data_tour.values[extra_length:, :]\n",
    "    \n",
    "    x_ts = []\n",
    "    for i in range(data.shape[1]):\n",
    "        line = data[:lengths[i], i]\n",
    "        x_ts.append(line)\n",
    "\n",
    "    x_ts_test = np.array(x_ts)\n",
    "    \n",
    "    x = np.empty((x_ts_train.shape[0], backcast_length))\n",
    "    y = np.empty((x_ts_train.shape[0], forecast_length))\n",
    "    \n",
    "    for i in range(x_ts_train.shape[0]):\n",
    "        \n",
    "        time_series_cleaned = x_ts_train[i]\n",
    "        target_cleaned = x_ts_test[i][:forecast_length]\n",
    "        \n",
    "        time_series_cleaned_forlearning_x = np.zeros((1, backcast_length))\n",
    "        time_series_cleaned_forlearning_y = np.zeros((1, forecast_length))\n",
    "\n",
    "        nonzero_input = time_series_cleaned[-backcast_length: ]\n",
    "        time_series_cleaned_forlearning_x[0, -len(nonzero_input):] = nonzero_input\n",
    "        time_series_cleaned_forlearning_y[0, : len(target_cleaned)] = target_cleaned\n",
    "\n",
    "        x[i] = time_series_cleaned_forlearning_x\n",
    "        y[i] = time_series_cleaned_forlearning_y\n",
    "\n",
    "    print(x.shape, y.shape)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving average for monthly M4 model on traffic and electricity\n",
    "\n",
    "Parameters to change:\n",
    "\n",
    "- test_dataset: traffic or electricity - dataset on which to predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_type = 'hourly'\n",
    "train_dataset = 'm4'\n",
    "test_dataset = 'traffic'\n",
    "\n",
    "# choosing parameters according to given frequency\n",
    "model_type = 'hourly'\n",
    "forecast_length = 48\n",
    "\n",
    "# choosing approprite function to load dataset and losses\n",
    "if test_dataset == 'electricity':\n",
    "    data_test_loader_func = get_electricity_data_testing_MA\n",
    "    numpy_loss_func = nd_loss_numpy\n",
    "    loss_func = nd_loss\n",
    "elif test_dataset == 'traffic':\n",
    "    data_test_loader_func = get_traffic_data_testing_MA\n",
    "    numpy_loss_func = nd_loss_numpy\n",
    "    loss_func = nd_loss\n",
    "    \n",
    "\n",
    "folder = './{}_checkpoints_{}/'.format(train_dataset, model_type)\n",
    "\n",
    "num_rand_inits = 5\n",
    "\n",
    "device = torch.device('cpu')\n",
    "batch_size = 1024\n",
    "\n",
    "final_results_list = []\n",
    "\n",
    "x, y_whole = data_test_loader_func(2 * forecast_length, forecast_length, data_type)\n",
    "\n",
    "y = np.zeros((y_whole.shape[0], forecast_length))\n",
    "y_nnz = y_whole[:, :forecast_length]\n",
    "y[:, :y_nnz.shape[1]] = y_nnz\n",
    "        \n",
    "has_neg_values = False\n",
    "if train_dataset == 'fred':\n",
    "    has_neg_values = True\n",
    "\n",
    "main_gens = [batcher(x, y, batch_size=batch_size, infinite=False)]\n",
    "for iteration in range(4):\n",
    "    if iteration != 0:\n",
    "        x = np.hstack([x, np.hstack(final_results_list)])[-backcast_length:]\n",
    "    preds_filename = Path('./predictions_eugene/{}_on_{}_{}_{}.npy'.\\\n",
    "                          format(train_dataset, test_dataset, data_type, iteration))\n",
    "\n",
    "    # remove previous predictions if any\n",
    "    if os.path.exists(preds_filename):\n",
    "        os.remove(preds_filename)\n",
    "\n",
    "    file = open(preds_filename, 'ab')\n",
    "    \n",
    "    for i in range(2, 8):\n",
    "        print('-------------------------------------')\n",
    "        print(i)\n",
    "\n",
    "        backcast_length = i * forecast_length\n",
    "\n",
    "        x, _ = data_test_loader_func(backcast_length, forecast_length, data_type)\n",
    "        y = np.zeros((y_whole.shape[0], forecast_length))\n",
    "        y_nnz = y_whole[:, iteration * forecast_length:(iteration + 1) * forecast_length]\n",
    "        y[:, :y_nnz.shape[1]] = y_nnz\n",
    "\n",
    "        max_consts = x.max(axis=1)\n",
    "        x_scaled = x.copy()\n",
    "        for j in range(x_scaled.shape[1]):\n",
    "            x_scaled[:, j] /= max_consts\n",
    "\n",
    "        data_gen = batcher(x_scaled, torch.tensor(max_consts), \n",
    "                       batch_size=batch_size, infinite=False)\n",
    "\n",
    "        data_gens = list(itertools.tee(data_gen, num_rand_inits))\n",
    "        main_gens = list(itertools.tee(main_gens[-1], num_rand_inits + 1))\n",
    "\n",
    "        for ind in range(1, num_rand_inits + 1):\n",
    "\n",
    "            checkpoint_name = '{}{}_share_{}H_G_{}_smape.th'.\\\n",
    "                                format(folder, model_type[:-2], i, ind)\n",
    "\n",
    "            print('--- Model ---')\n",
    "            n_stacks = 30\n",
    "            net = NBeatsNet(device=device,\n",
    "                            stack_types=[NBeatsNet.GENERIC_BLOCK] * n_stacks,\n",
    "                            forecast_length=forecast_length,\n",
    "                            thetas_dims=[4] * n_stacks,\n",
    "                            nb_blocks_per_stack=1,\n",
    "                            backcast_length=backcast_length,\n",
    "                            hidden_layer_units=512,\n",
    "                            share_weights_in_stack=True\n",
    "                            )\n",
    "            get_predictions(net, data_gens[ind - 1], main_gens[ind - 1], \\\n",
    "                            device, loss_func, \\\n",
    "                            checkpoint_name, forecast_length, file, has_neg_values)\n",
    "\n",
    "            print('\\n\\n')\n",
    "\n",
    "    file.close()\n",
    "\n",
    "    # ensemble predictions\n",
    "    shape = (num_rand_inits * 6, y.shape[0], y.shape[1])\n",
    "    fp = np.memmap(preds_filename, dtype=np.float64, mode='r', shape=shape)\n",
    "\n",
    "    final_results_1 = np.zeros(y.shape)\n",
    "    for i in range(shape[1]):\n",
    "        final_results_1[i] = np.median(fp[:, i, :], axis=0)\n",
    "\n",
    "    x, _ = data_test_loader_func(2 * forecast_length, forecast_length, data_type)\n",
    "\n",
    "    print('TOTAL SMAPE LOSS:', numpy_loss_func(final_results_1, y))\n",
    "\n",
    "    # plot predictions\n",
    "    plot_model_forecast(x, y, final_results_1, x.shape[1], y.shape[1], 111)\n",
    "\n",
    "    final_results_list.append(final_results_1)\n",
    "    \n",
    "final_results = np.hstack(final_results_list)[:, :y_whole.shape[1]]\n",
    "numpy_loss_func(final_results, y_whole)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results M4 moving average\n",
    "\n",
    "M4 traffic hourly - 0.2586939005945968\n",
    "\n",
    "\n",
    "M4 electricity hourly - 0.1682311979622215"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
